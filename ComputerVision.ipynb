{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e34577-30f6-4a54-809d-89fc4415ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20952c6-4aee-47a9-bdc2-c46dfcdf30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8ef285-1ca6-4fe2-94fd-0c1288f02d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "resim = cv2.imread('input.jpg')  # resim dosyasını rakam olarak okuma \n",
    "cv2.imshow('Merhaba', resim) # rakamları resme döndürdü, resime başlık da ekliyebiliyoruz (Merhaba)\n",
    "cv2.waitKey() # bir tuşa basana kadar bekle, diğer türlü hemen açılıp kapanıyor \n",
    "cv2.destroyAllWindows() # bir tuşa basınca kapat, çarpıdan kapatma çünkü tanımlamadık o işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f1510e-d373-4978-a697-b4f69fe8e848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12, 18, 31],\n",
       "        [12, 18, 31],\n",
       "        [11, 17, 30],\n",
       "        ...,\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38]],\n",
       "\n",
       "       [[12, 18, 31],\n",
       "        [12, 18, 31],\n",
       "        [12, 18, 31],\n",
       "        ...,\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38]],\n",
       "\n",
       "       [[12, 18, 31],\n",
       "        [12, 18, 31],\n",
       "        [12, 18, 31],\n",
       "        ...,\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38],\n",
       "        [21, 24, 38]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4,  7, 12],\n",
       "        [ 4,  7, 12],\n",
       "        [ 3,  7, 12],\n",
       "        ...,\n",
       "        [18, 23, 38],\n",
       "        [19, 24, 39],\n",
       "        [20, 25, 40]],\n",
       "\n",
       "       [[ 3,  6, 11],\n",
       "        [ 3,  6, 11],\n",
       "        [ 3,  6, 11],\n",
       "        ...,\n",
       "        [18, 23, 38],\n",
       "        [19, 24, 39],\n",
       "        [20, 25, 40]],\n",
       "\n",
       "       [[ 3,  6, 11],\n",
       "        [ 3,  6, 11],\n",
       "        [ 2,  5, 10],\n",
       "        ...,\n",
       "        [18, 23, 38],\n",
       "        [18, 23, 38],\n",
       "        [19, 24, 39]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d588891-666f-47c4-b5a1-ef08ad60516d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 1245, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227d9212-3da0-4312-8914-0c1077c79b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "checkboard = np.zeros((9,9))\n",
    "checkboard[0::2,1::2] = 1\n",
    "checkboard[1::2,0::2] = 1\n",
    "print(checkboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9c4278-e47a-4d63-b4ad-82cd9402f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff53791-c569-43b3-a057-f58400de0f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a5e4d8a30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(checkboard, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46dddb33-b600-4486-b7c8-a7c6ba536ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53601742-ddc1-4a3b-b02e-501702ed5d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28888887, 0.32941177, 0.38039216, 0.50326794, 0.47973856,\n",
       "        0.50457519, 0.55947715, 0.54901963, 0.56732029, 0.57516342,\n",
       "        0.59738559, 0.61307186, 0.59607846, 0.56078434, 0.54248363,\n",
       "        0.49281046, 0.45359477, 0.44183007, 0.2522876 , 0.23529412,\n",
       "        0.4261438 , 0.49673203, 0.72418302, 0.69934636, 0.43529412],\n",
       "       [0.29411766, 0.33333334, 0.44052288, 0.52026147, 0.49934641,\n",
       "        0.53464049, 0.55424833, 0.59869283, 0.6156863 , 0.61960787,\n",
       "        0.620915  , 0.63660127, 0.62875813, 0.6326797 , 0.59215689,\n",
       "        0.52418303, 0.47581699, 0.44705883, 0.34640524, 0.32287583,\n",
       "        0.33202612, 0.59738559, 0.81830066, 0.77777773, 0.27843139],\n",
       "       [0.35294119, 0.41568628, 0.42745098, 0.48104575, 0.50457519,\n",
       "        0.52287579, 0.53594774, 0.63529414, 0.65359479, 0.620915  ,\n",
       "        0.61830068, 0.64444441, 0.61830068, 0.61830068, 0.60000002,\n",
       "        0.53856206, 0.46405229, 0.43137255, 0.37254903, 0.37908494,\n",
       "        0.29411766, 0.50065356, 0.60915029, 0.53856206, 0.36732024],\n",
       "       [0.41176471, 0.43006536, 0.49542484, 0.48627451, 0.50980395,\n",
       "        0.52679735, 0.53071892, 0.60915029, 0.57516342, 0.59869283,\n",
       "        0.63006538, 0.64705884, 0.63921571, 0.63398695, 0.59738559,\n",
       "        0.54248363, 0.46013072, 0.41699347, 0.39607844, 0.30718955,\n",
       "        0.26274511, 0.48627451, 0.26143789, 0.1856209 , 0.19477125],\n",
       "       [0.43137255, 0.49673203, 0.47712418, 0.46797386, 0.48627451,\n",
       "        0.53071892, 0.5411765 , 0.60130715, 0.63660127, 0.61830068,\n",
       "        0.59869283, 0.61437911, 0.63006538, 0.61699343, 0.5581699 ,\n",
       "        0.5281046 , 0.47973856, 0.45228758, 0.4130719 , 0.3594771 ,\n",
       "        0.23921569, 0.36993465, 0.1856209 , 0.16732027, 0.19084968],\n",
       "       [0.48104575, 0.47320262, 0.39869279, 0.43921569, 0.47973856,\n",
       "        0.54248363, 0.55032676, 0.58954245, 0.62614381, 0.61960787,\n",
       "        0.61960787, 0.62222224, 0.63137257, 0.620915  , 0.57908499,\n",
       "        0.54771245, 0.49542484, 0.43137255, 0.44052288, 0.27712417,\n",
       "        0.22222222, 0.41437906, 0.1751634 , 0.1751634 , 0.19084968],\n",
       "       [0.42483661, 0.42222223, 0.35816994, 0.46797386, 0.50326794,\n",
       "        0.51503265, 0.43529412, 0.49019608, 0.53725493, 0.49803922,\n",
       "        0.47189543, 0.55947715, 0.56209147, 0.55424833, 0.42091504,\n",
       "        0.36862746, 0.28627452, 0.29934642, 0.34640524, 0.28627452,\n",
       "        0.32549021, 0.31895426, 0.18431373, 0.18431373, 0.20261438],\n",
       "       [0.36862746, 0.31764707, 0.4627451 , 0.49803922, 0.48235294,\n",
       "        0.4379085 , 0.43921569, 0.38039216, 0.3019608 , 0.31111112,\n",
       "        0.40915033, 0.44836602, 0.49542484, 0.47189543, 0.33725491,\n",
       "        0.28104573, 0.41437906, 0.41437906, 0.35032681, 0.43267974,\n",
       "        0.37385622, 0.31764707, 0.17908497, 0.19869281, 0.19869281],\n",
       "       [0.20784314, 0.29411766, 0.50718951, 0.48104575, 0.47450981,\n",
       "        0.45228758, 0.47189543, 0.42745098, 0.28235295, 0.27189544,\n",
       "        0.28888887, 0.45751634, 0.61045754, 0.34509805, 0.25098041,\n",
       "        0.17908497, 0.16078432, 0.2       , 0.43006536, 0.47712418,\n",
       "        0.29934642, 0.59346402, 0.41568628, 0.31503269, 0.1738562 ],\n",
       "       [0.26274511, 0.27973858, 0.46928105, 0.50718951, 0.56601304,\n",
       "        0.49803922, 0.4509804 , 0.55163401, 0.31111112, 0.52287579,\n",
       "        0.52549022, 0.52026147, 0.59346402, 0.42091504, 0.43921569,\n",
       "        0.50065356, 0.46535948, 0.5281046 , 0.47320262, 0.45228758,\n",
       "        0.21699347, 0.81045753, 0.74640518, 0.35424837, 0.15294118],\n",
       "       [0.30326799, 0.4130719 , 0.45882353, 0.50588238, 0.58562088,\n",
       "        0.57124186, 0.57516342, 0.59607846, 0.53986931, 0.5411765 ,\n",
       "        0.58300656, 0.48366013, 0.55555558, 0.44444445, 0.47320262,\n",
       "        0.52026147, 0.52026147, 0.49019608, 0.53856206, 0.47058824,\n",
       "        0.41045749, 0.80130714, 0.71241832, 0.33464053, 0.1633987 ],\n",
       "       [0.42091504, 0.40522876, 0.43529412, 0.49150327, 0.55555558,\n",
       "        0.60130715, 0.61045754, 0.63006538, 0.61176473, 0.65620911,\n",
       "        0.5281046 , 0.53333336, 0.56601304, 0.48496732, 0.46143791,\n",
       "        0.5281046 , 0.56601304, 0.55555558, 0.48235294, 0.43921569,\n",
       "        0.47581699, 0.50326794, 0.35555553, 0.28888887, 0.20130718],\n",
       "       [0.53725493, 0.43137255, 0.4627451 , 0.47843137, 0.50065356,\n",
       "        0.57124186, 0.64444441, 0.627451  , 0.64836597, 0.64052284,\n",
       "        0.50457519, 0.5411765 , 0.63660127, 0.55555558, 0.44967321,\n",
       "        0.48496732, 0.61437911, 0.55686277, 0.44183007, 0.42091504,\n",
       "        0.42483661, 0.19738561, 0.21568628, 0.22875817, 0.22875817],\n",
       "       [0.42483661, 0.44313726, 0.44444445, 0.45620915, 0.49019608,\n",
       "        0.50588238, 0.57908499, 0.60130715, 0.6026144 , 0.53071892,\n",
       "        0.54509807, 0.55163401, 0.56078434, 0.61176473, 0.43398693,\n",
       "        0.41437906, 0.48235294, 0.49803922, 0.42091504, 0.41045749,\n",
       "        0.38954249, 0.19084968, 0.21960784, 0.22614379, 0.23529412],\n",
       "       [0.46797386, 0.43529412, 0.45228758, 0.46797386, 0.50457519,\n",
       "        0.4875817 , 0.52026147, 0.53594774, 0.50196081, 0.47320262,\n",
       "        0.39477122, 0.29803923, 0.49411765, 0.49281046, 0.26797387,\n",
       "        0.40784314, 0.38039216, 0.44705883, 0.38954249, 0.39869279,\n",
       "        0.20261438, 0.18300654, 0.20915033, 0.22875817, 0.23529412],\n",
       "       [0.4261438 , 0.39607844, 0.44575164, 0.46143791, 0.51241833,\n",
       "        0.47450981, 0.49019608, 0.49673203, 0.4509804 , 0.5581699 ,\n",
       "        0.58039218, 0.54901963, 0.40653592, 0.40261436, 0.41960785,\n",
       "        0.4261438 , 0.35686275, 0.3764706 , 0.37516338, 0.4130719 ,\n",
       "        0.1751634 , 0.17777777, 0.2130719 , 0.21699347, 0.23137255],\n",
       "       [0.37124181, 0.37516338, 0.41437906, 0.44705883, 0.49673203,\n",
       "        0.49019608, 0.50326794, 0.51503265, 0.50718951, 0.50980395,\n",
       "        0.58562088, 0.60392159, 0.55032676, 0.55163401, 0.47320262,\n",
       "        0.41045749, 0.37254903, 0.4013072 , 0.4130719 , 0.36732024,\n",
       "        0.4130719 , 0.30718955, 0.18692811, 0.30849671, 0.22614379],\n",
       "       [0.13986929, 0.08888888, 0.38562092, 0.44183007, 0.46535948,\n",
       "        0.52287579, 0.53594774, 0.50588238, 0.48104575, 0.46928105,\n",
       "        0.49019608, 0.54771245, 0.53725493, 0.54901963, 0.46666667,\n",
       "        0.39084965, 0.3764706 , 0.4261438 , 0.37908494, 0.20392157,\n",
       "        0.08627451, 0.09019608, 0.1124183 , 0.0627451 , 0.22745098],\n",
       "       [0.10980392, 0.09934641, 0.32810456, 0.41960785, 0.4627451 ,\n",
       "        0.50065356, 0.5464052 , 0.50326794, 0.48104575, 0.36601308,\n",
       "        0.16470589, 0.09019608, 0.11503268, 0.10980392, 0.06535947,\n",
       "        0.2496732 , 0.41960785, 0.43398693, 0.37908494, 0.08627451,\n",
       "        0.09281045, 0.06797386, 0.075817  , 0.03660131, 0.06797386],\n",
       "       [0.09673202, 0.44313726, 0.49934641, 0.40000001, 0.46535948,\n",
       "        0.47581699, 0.51111108, 0.53333336, 0.4875817 , 0.15163399,\n",
       "        0.13202615, 0.16732027, 0.21437909, 0.21176471, 0.16601306,\n",
       "        0.32287583, 0.39477122, 0.43529412, 0.37777779, 0.09019608,\n",
       "        0.07843138, 0.0875817 , 0.06797386, 0.04836601, 0.075817  ],\n",
       "       [0.10588235, 0.44967321, 0.67843139, 0.35686275, 0.41437906,\n",
       "        0.42745098, 0.49542484, 0.49542484, 0.52026147, 0.56862748,\n",
       "        0.56862748, 0.44967321, 0.44183007, 0.52418303, 0.43137255,\n",
       "        0.40784314, 0.49934641, 0.40522876, 0.15163399, 0.10196079,\n",
       "        0.07189543, 0.06797386, 0.07189543, 0.06013072, 0.07189543],\n",
       "       [0.10326798, 0.26013073, 0.84444445, 0.37385622, 0.37124181,\n",
       "        0.41176471, 0.46797386, 0.5411765 , 0.54509807, 0.51895422,\n",
       "        0.5281046 , 0.55163401, 0.53986931, 0.55163401, 0.41176471,\n",
       "        0.41437906, 0.47712418, 0.35816994, 0.07712418, 0.0875817 ,\n",
       "        0.07843138, 0.06013072, 0.07189543, 0.07189543, 0.06797386],\n",
       "       [0.10980392, 0.10588235, 0.80653596, 0.77516341, 0.36732024,\n",
       "        0.39346406, 0.42222223, 0.53202617, 0.57908499, 0.52156866,\n",
       "        0.47973856, 0.44444445, 0.39477122, 0.38954249, 0.35816994,\n",
       "        0.42745098, 0.43137255, 0.14509805, 0.08366013, 0.08627451,\n",
       "        0.075817  , 0.06013072, 0.05620915, 0.07189543, 0.075817  ],\n",
       "       [0.10588235, 0.11372549, 0.81307185, 0.80000001, 0.7647059 ,\n",
       "        0.38039216, 0.39215687, 0.46405229, 0.58300656, 0.56732029,\n",
       "        0.53986931, 0.50849676, 0.49673203, 0.46143791, 0.42745098,\n",
       "        0.48235294, 0.30980393, 0.0875817 , 0.07320261, 0.08366013,\n",
       "        0.0875817 , 0.06405229, 0.04444444, 0.06013072, 0.07189543],\n",
       "       [0.09150327, 0.0875817 , 0.66405225, 0.84052289, 0.8143791 ,\n",
       "        0.82222223, 0.37777779, 0.36862746, 0.52679735, 0.60130715,\n",
       "        0.59477127, 0.57385617, 0.55686277, 0.54248363, 0.51764709,\n",
       "        0.45620915, 0.16732027, 0.08235294, 0.07058824, 0.06797386,\n",
       "        0.07450981, 0.06013072, 0.05620915, 0.06405229, 0.06797386]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bush = data.lfw_subset()\n",
    "bush = bush[0,:,:]\n",
    "bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6580dc71-d239-42fa-81c6-1e4640594623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(bush, cmap='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb3c792-305e-4e75-94ec-319bf7f3b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 50x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(0.5,0.5))\n",
    "plt.imshow(bush, cmap='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc78cc0-0352-4b2c-9f60-1a438b7c50b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "VersionRequirementError",
     "evalue": "\n\nSphinx<4.0.2 is incompatible with Jinja2>=3.1.\nIf you wish to continue using sphinx<4.0.2 you need to pin Jinja2<3.1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mVersionRequirementError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24612\\1825314095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastronaut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\data\\_fetchers.py\u001b[0m in \u001b[0;36mastronaut\u001b[1;34m()\u001b[0m\n\u001b[0;32m    399\u001b[0m     \"\"\"\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/astronaut.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\data\\_fetchers.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, as_gray)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;31m# importing io is quite slow since it scans all the backends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;31m# we lazy import it here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_gray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\io\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_image_stack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mtemplate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_remove_plugin_param_template\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m )\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEPRECATED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \"\"\"Load an image from file.\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodify_docstring\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             newdoc = _docstring_add_deprecated(\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py\u001b[0m in \u001b[0;36m_docstring_add_deprecated\u001b[1;34m(func, kwarg_mapping, deprecated_version)\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mnumpydoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocscrape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctionDoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;31m# Return an unmodified docstring if numpydoc is not available.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\numpydoc\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0m_verify_sphinx_jinja\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\numpydoc\\__init__.py\u001b[0m in \u001b[0;36m_verify_sphinx_jinja\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0msphinx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersionRequirementError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             raise VersionRequirementError(\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[1;34m\"\\n\\nSphinx<4.0.2 is incompatible with Jinja2>=3.1.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;34m\"If you wish to continue using sphinx<4.0.2 you need to pin \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mVersionRequirementError\u001b[0m: \n\nSphinx<4.0.2 is incompatible with Jinja2>=3.1.\nIf you wish to continue using sphinx<4.0.2 you need to pin Jinja2<3.1."
     ]
    }
   ],
   "source": [
    "image =data.astronaut()\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a1bd98e-ea7a-4397-9a6d-0d59a34f29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "sb = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Siyah Beyaz', sb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e10f1b8b-32b8-4097-b673-2a63d6eb98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daha kolay yolu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077946d2-12c7-41cc-99c0-7deac2b85314",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg',0) # 0 koyduğumuzda siyah beyaza dönüyor  \n",
    "cv2.imshow('Siyah Beyaz', sb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee5cddef-3f96-4aa1-a86f-449ebb52baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #insan gözünün gördüğü şekilde \n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('HSV', hsv)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e99237c-0d39-4c64-9283-e34d363d3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kanllarına ayırdık\n",
    "image = cv2.imread('input.jpg')\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('HSV image', hsv_image[:,:,:])\n",
    "cv2.imshow('Hue channel', hsv_image[:,:,0])\n",
    "cv2.imshow('Saturation channel', hsv_image[:,:,1])\n",
    "cv2.imshow('Calue channel', hsv_image[:,:,2])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09063732-ddfb-4da9-a388-8424ab81a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830, 1245)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "B,G,R = cv2.split(image)\n",
    "# önce mavi tonlar, sonra yeşil, en son ise kırmızı tonlar\n",
    "print(B.shape)\n",
    "cv2.imshow('Red', R)\n",
    "cv2.imshow('Green', G)\n",
    "cv2.imshow('Blue', B)\n",
    "# Bu resimlerin üçü de gri olarak çıkıyor, bu resimlerdeki grinin tonlarından rgb'nin tonlarını öğreniyoruz  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "merged = cv2.merge([B,G,R])\n",
    "cv2.imshow('Merged',merged)\n",
    "merged = cv2.merge([B+100, G, R+100])\n",
    "# Mesela bir insan fotoğrafının rakamlarını makineye öğretirsek, bu rakamlara (yukarıdaki gibi)\n",
    "# rakamlar ekleterek rasgele insan yüzleri oluşturabiliriz\n",
    "cv2.imshow('Merged with Blue Amplifies', merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b78f1-06bd-4630-b357-6d0711fa86a4",
   "metadata": {},
   "source": [
    "### Otonom araçlar yollarını nasıl bulur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b201c566-0143-4a77-aa03-662db5fea364",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg',0)\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0,1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1,0, ksize=5)\n",
    "\n",
    "cv2.imshow('Rotated Im age', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('Sobel_OR', sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09673d-531e-46b3-8321-739abafecc42",
   "metadata": {},
   "source": [
    "**sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)** ifadesi, iki görüntüdeki piksel değerlerini bit düzeyinde OR işlemi ile birleştirir. Bu genellikle Sobel kenar algılama sonuçlarını birleştirmek için kullanılır. İşte bu işlemin ne anlama geldiği ve nasıl çalıştığı hakkında kısa bir açıklama:\n",
    "\n",
    "sobel_x: X yönündeki kenarları tespit eden Sobel filtresi uygulaması sonucu elde edilen görüntü.\n",
    "\n",
    "sobel_y: Y yönündeki kenarları tespit eden Sobel filtresi uygulaması sonucu elde edilen görüntü.\n",
    "\n",
    "cv2.bitwise_or(): İki görüntüdeki her pikselin bit düzeyinde OR işlemini yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "770b7884-7bc9-475c-8d88-0ec8f1742fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)    \n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    ret,mask = cv2.threshold(canny_edges,250,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask \n",
    "\n",
    "cap = cv2.VideoCapture('My_Video.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Our live Sketcher', sketch(frame))\n",
    "    if cv2.waitKey(1) == 13: # 13 -> enter \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n",
    "\n",
    "# bilgisayarda kamera olmadığı için hata verir, o yüzden çalıştıramadım \n",
    "# bizim canlı olarak yüz ve vücut hatlarımızı belirler (Canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5870338c-40e8-48e6-9dc9-33e454d00bf1",
   "metadata": {},
   "source": [
    "cap.release() kullanarak video yakalama nesnesini kapatır ve kaynakları düzgün bir şekilde yönetirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ebad4596-de7e-4843-8fce-ba58d71f5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is Waldo\n",
    "image = cv2.imread('WaldoBeach.jpg')\n",
    "\n",
    "cv2.imshow('Where is Waldo', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.imread('WaldoBeach.jpg', 0)\n",
    "waldo = cv2.imread('Waldo.jpg', 0)\n",
    "\n",
    "result = cv2.matchTemplate(gray, waldo, cv2.TM_CCOEFF) # resmin içinde resim araması yapıyoruz\n",
    "# gray isimli resimde waldoyu ara \n",
    "minval, maxval, minloc, maxloc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = maxloc\n",
    "bottom_right = (top_left[0]+50, top_left[1]+50)\n",
    "# top_left[0]+50, x koordinatına 50 piksel eklerken (sağ), top_left[1]+50 y koordinatına 50 piksel ekler (aşağı)\n",
    "cv2.rectangle(image, top_left, bottom_right,(0,0,255),5) # kırmızı çizgi, kalınlığı 5 \n",
    "\n",
    "cv2.imshow('Where is Waldo', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ilk başta resmi aldık, siyah beyaza çevirdik, resmin içinde resmi bulduk, dikdörtgen ile işaretledik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb4d002-e5ae-4977-9c20-b38a52c41edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ba6e17-d0a0-40b0-9718-78749d72adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imutils \n",
    "image = cv2.imread('input.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "flipped = cv2.flip(image,1) # ters çevirmek/ çevirmek \n",
    "cv2.imshow('Horizontal Flipped', flipped)\n",
    "\n",
    "flipped = cv2.flip(image,0) # ters çevirmek/ çevirmek \n",
    "cv2.imshow('Vertical Flipped', flipped)\n",
    "\n",
    "flipped = cv2.flip(image,-1) # ters çevirmek/ çevirmek \n",
    "cv2.imshow('Bot Flipped', flipped)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9330cee-a7d4-4cd0-a7bc-0eab5ff4bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendi videonu çekme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30445e9a-7286-48bb-aee1-57ea62aa9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('kediler.mp4') \n",
    "# 0 genelde laptopun kamerası, 1 de genelde harici bir kamerayı ifade ediyor \n",
    "while True:\n",
    "    ret,frame = cap.read() \n",
    "# ret bir sonraki kare var mı demek, frame ise current kareyi temsil eder  \n",
    "    if ret:\n",
    "        cv2.imshow('Bendeniz', frame)\n",
    "    else: \n",
    "        break \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b95fe927-7519-47ea-be37-66718c75208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('cars.mp4') \n",
    "while True:\n",
    "    ret,frame = cap.read() \n",
    "    # ret bir sonraki kare var mı demek, frame ise current kareyi temsil eder\n",
    "    if ret:\n",
    "        cv2.imshow('Otoban', frame)\n",
    "    else: \n",
    "        break \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7c6ca0-ce41-4a13-a971-b98288d88866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kendi fotonu çekip kayıt etme, kamera olmadığı için videoyu kullanacağım\n",
    "selfie = cv2.VideoCapture('cars.mp4').read()[1] # [1] -> ilk kareden fotoyu çek\n",
    "cv2.imwrite('ben.jpg', selfie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9213c-d2e1-4585-b6cd-c230d67249fe",
   "metadata": {},
   "source": [
    "Kamera hareketi nasıl anlar? Bir önceki kare bir sonraki kare arasındaki sayıların değişmesi ile anlarlar, yalnız değişikliğin belirli bir büyüklükte olması lazım, sinek vs geçtiğinde sıkıntı olmaması için  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3db820dd-fd95-4f88-bde4-fff9983f6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kod ile iki kare arasındaki farkı hesaplarız\n",
    "cap = cv2.VideoCapture('cars.mp4')\n",
    "ret1,frame1 = cap.read() #ilk okuma\n",
    "ret2,frame2 = cap.read() #ikinci okuma \n",
    "\n",
    "while True: # kamera açık olduğu müddetçe \n",
    "    frame1sb = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) # önce siyah beyaza çevirmemiz gerekiyor \n",
    "    frame2sb = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff = cv2.absdiff(frame1sb, frame2sb)\n",
    "    cv2.imshow('Motion', diff)\n",
    "    frame1 = frame2 \n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: \n",
    "        cap.release()\n",
    "        break \n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6fa815f0-857b-4356-830d-f94fc2f93be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kod ile iki kare arasındaki farkı hesaplarız\n",
    "cap = cv2.VideoCapture('kediler.mp4')\n",
    "ret1,frame1 = cap.read() #ilk okuma\n",
    "ret2,frame2 = cap.read() #ikinci okuma \n",
    "\n",
    "while True: # kamera açık olduğu müddetçe \n",
    "    frame1sb = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) # önce siyah beyaza çevirmemiz gerekiyor \n",
    "    frame2sb = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff = cv2.absdiff(frame1sb, frame2sb)\n",
    "    cv2.imshow('Motion', diff)\n",
    "    frame1 = frame2 \n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: \n",
    "        cap.release()\n",
    "        break \n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "391d6b59-c010-4335-a74a-6106668109ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu kod ile iki kare arasındaki farkı hesaplarız\n",
    "cap = cv2.VideoCapture('airplanes.mp4')\n",
    "ret1,frame1 = cap.read() #ilk okuma\n",
    "ret2,frame2 = cap.read() #ikinci okuma \n",
    "\n",
    "while True: # kamera açık olduğu müddetçe \n",
    "    frame1sb = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) # önce siyah beyaza çevirmemiz gerekiyor \n",
    "    frame2sb = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff = cv2.absdiff(frame1sb, frame2sb)\n",
    "    cv2.imshow('Motion', diff)\n",
    "    frame1 = frame2 \n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: \n",
    "        cap.release()\n",
    "        break \n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0588b22c-2764-4ae7-ab04-fe714481c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('airplanes.mp4')\n",
    "ret1,frame1 = cap.read() #ilk okuma\n",
    "ret2,frame2 = cap.read() #ikinci okuma \n",
    "\n",
    "while True: # kamera açık olduğu müddetçe \n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) # önce siyah beyaza çevirmemiz gerekiyor \n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0) # frame blur görüntüye bulanıklık katmak için kullanılır \n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur, frame2_blur)\n",
    "\n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    masked = cv2.bitwise_and(frame1, frame1, mask=thresh)\n",
    "    white_pixels = np.sum(thresh)/255\n",
    "\n",
    "    rows,cols = thresh.shape\n",
    "    total = rows*cols\n",
    "\n",
    "    if white_pixels > 0.01*total:\n",
    "        font = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "        cv2.putText(frame1, 'Movement Detected - Hareket Var',(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        # görüntüye yazı koymak için kullanılır - (10,50) Metnin başlangıç noktası - 1 Font ölçeği - 2 Metin kalınlığı\n",
    "        # cv2.LINE_AA: Metin çiziminde kullanılan çizgi tipi. Anti-aliasing ile daha pürüzsüz bir görünüm sağlar.\n",
    "\n",
    "    cv2.imshow('Motion', frame1)\n",
    "    frame1 = frame2 \n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret: \n",
    "        break \n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27 or key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768e322f-6d4f-4407-be91-5becc1e9d536",
   "metadata": {},
   "source": [
    "**thresh = cv2.threshold(diff, 20, 255, cv2.THRESH_BINARY)[1]** ifadesi, \n",
    "bir görüntüdeki pikselleri belirli bir eşik değerine göre ikili (binary) hale getirmek için kullanılır.\n",
    "\n",
    "cv2.threshold Fonksiyonu:\n",
    "\n",
    "Bu fonksiyon, bir görüntünün piksellerini belirli bir eşik değerine göre değiştirir.\n",
    "İki ana parametre alır:\n",
    "\n",
    "diff: Eşikleme işlemi uygulanacak görüntü (genellikle bir fark görüntüsü).\n",
    "20: Eşik değeri. Bu değerin altındaki pikseller sıfıra (siyah), üstündeki pikseller ise\n",
    "maksimum değere (genellikle 255, beyaz) ayarlanır.\n",
    "\n",
    "255: Eşikleme sonrası beyaz pikselin değeri.\n",
    "\n",
    "cv2.THRESH_BINARY: Eşikleme türü. Bu durumda, pikseller ya 0 ya da 255 değerini alır.\n",
    "Sonuç:\n",
    "\n",
    "Fonksiyon, iki değer döndürür: birincisi, uygulanan eşik değerinin başarıyla ayarlandığını\n",
    "gösteren bir değer; ikincisi ise eşiklenmiş görüntüdür. thresh değişkenine atanan [1],\n",
    "bu ikinci değeri alır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779fdeb-d3a7-451f-9581-55e83f85ee3d",
   "metadata": {},
   "source": [
    "**cv2.dilate Fonksiyonu**:\n",
    "\n",
    "cv2.dilate Fonksiyonu:\n",
    "\n",
    "Bu fonksiyon, bir görüntüdeki beyaz piksellerin (genellikle 255) etrafındaki alanı genişletir. Bu, kenarları daha belirgin hale getirmek veya küçük boşlukları doldurmak için kullanılır.\n",
    "Parametreler:\n",
    "\n",
    "thresh: Genişletme işlemi uygulanacak görüntü. Genellikle ikili (binary) bir görüntü olmalıdır.\n",
    "\n",
    "None: Kernel (filtre) boyutu. Eğer None verilirse, otomatik olarak 3x3 boyutunda bir çekirdek kullanılır. Farklı kernel boyutları kullanarak genişletme etkisini değiştirebilirsiniz.\n",
    "\n",
    "iterations=2: İşlemin kaç kez uygulanacağını belirtir. Bu değer arttıkça, piksellerin genişleme etkisi de artar.\n",
    "\n",
    "Kullanım Amacı\n",
    "\n",
    "Nesne Tespiti: Nesnelerin daha belirgin hale gelmesi için kullanılır. Örneğin, hareket tespiti sonrası elde edilen görüntüdeki nesnelerin daha belirgin olması sağlanır.\n",
    "\n",
    "Boşluk Doldurma: Küçük boşlukları ve delikleri doldurarak nesnelerin daha sağlam görünmesini sağlar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994aa00f-b9de-49fe-a88b-4de17831c4b9",
   "metadata": {},
   "source": [
    "**masked = cv2.bitwise_and(frame1, frame1, mask=thresh)** ifadesi, bir görüntüde belirli alanları maskelemek için kullanılan bir işlemdir. İşte detaylı açıklaması:\n",
    "\n",
    "Açıklama\n",
    "cv2.bitwise_and Fonksiyonu:\n",
    "\n",
    "Bu fonksiyon, iki görüntü arasındaki bitwise AND işlemini gerçekleştirir. Yani, her iki görüntüde de aynı piksel konumunda beyaz (255) olan pikseller, sonuçta beyaz olarak kalır; diğer pikseller siyah (0) olur.\n",
    "Parametreler:\n",
    "\n",
    "frame1: İlk görüntü (genellikle orijinal görüntü).\n",
    "frame1: İkinci görüntü. Burada aynı görüntü kullanıldığı için, sonuçta sadece maske ile belirtilen alanlar görünür hale gelecektir.\n",
    "mask=thresh: Uygulamak istediğiniz maske. thresh değişkeni, genellikle ikili (binary) bir görüntüdür ve hangi bölgelerin görünür olacağını belirler.\n",
    "Kullanım Amacı\n",
    "Nesne İzleme: Belirli nesneleri veya alanları izole etmek için maskeleme işlemi yapar. Örneğin, hareket eden nesneleri arka plandan ayırmak için kullanılır.\n",
    "Görüntü İşleme: İstenmeyen alanları gizleyerek yalnızca belirli bölgeleri incelemek için kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed2cbd-23a5-45fa-b718-2f460edb068d",
   "metadata": {},
   "source": [
    "**white_pixels = np.sum(thresh) / 255** ifadesi, ikili bir görüntüdeki beyaz piksellerin sayısını hesaplamak için kullanılır. İşte detaylı açıklaması:\n",
    "\n",
    "Açıklama\n",
    "np.sum(thresh):\n",
    "\n",
    "Bu ifade, thresh adlı ikili görüntüdeki tüm piksellerin toplamını hesaplar. İkili görüntüde beyaz pikseller (255) ve siyah pikseller (0) bulunur. Dolayısıyla, toplam, beyaz piksellerin sayısını doğrudan vermez.\n",
    "Bölme İşlemi (/ 255):\n",
    "\n",
    "Beyaz piksellerin toplamını elde etmek için, toplam piksel değerini 255'e böleriz. Çünkü her beyaz piksel 255 değerine sahiptir. Bu işlem sonucunda, toplam beyaz piksel sayısını verir.\n",
    "Kullanım Amacı\n",
    "Nesne Tespiti: Görüntüdeki beyaz piksellerin sayısını bilmek, belirli nesnelerin veya hareketlerin tespiti için yararlıdır. Örneğin, bir nesnenin boyutunu veya hareket miktarını belirlemek için kullanılabilir.\n",
    "\n",
    "Örnek Senaryo:\n",
    "\n",
    "Eğer bir video akışında hareket eden nesneleri tespit ediyorsanız, beyaz piksellerin sayısını hesaplayarak, hangi nesnelerin ne kadar büyük olduğunu veya hareket ettiklerini analiz edebilirsiniz. Bu bilgi, nesne izleme ve analiz süreçlerinde önemli bir rol oynar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d1b37530-e1a5-4db5-b871-fc18e2420b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours Found = 4\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('bunchofshapes.jpg')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged) # bu satır gereksiz\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print('Number of Contours Found = ' + str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image, contours,-1,(0,255,0), thickness=2)\n",
    "# bir görüntü üzerinde tespit edilen konturları çizmek için kullanılır.\n",
    "# -1 yazan kısım çizilecek contours indeksini belirtir, -1 hepsini çizer \n",
    "\n",
    "cv2.imshow('Countours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# burada önce nesnelerin Canny ile kenarlarını belirledik, ardından belirlediğimiz kenarların \n",
    "# sınırlar noktalarını findContours ile belirledik ve kaydettik, \n",
    "# bu belirlediğimiz contourları da drawContours ile çizdik\n",
    "# nesne sayısını ise yine findContours ile bulduk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0451b0d-6ec3-4b19-85cc-59980422c1f5",
   "metadata": {},
   "source": [
    "**contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)** ifadesi, bir görüntüdeki konturları (kenarları) tespit etmek için kullanılır. \n",
    "\n",
    "**edges**:\n",
    "\n",
    "Konturları tespit etmek için kullanılan görüntü. Genellikle kenar tespiti yapılmış, ikili (binary) bir görüntüdür.\n",
    "\n",
    "**cv2.RETR_EXTERNAL:**\n",
    "\n",
    "Kontur alma yöntemi. Bu parametre, yalnızca dış konturları (en dıştaki şekilleri) tespit eder. İç konturları göz ardı eder.\n",
    "\n",
    "**cv2.CHAIN_APPROX_NONE:**\n",
    "\n",
    "Kontur noktalarının saklanma şekli. Bu parametre, tüm kontur noktalarını kaydeder. Daha az bellek kullanmak için cv2.CHAIN_APPROX_SIMPLE kullanılabilir; bu durumda sadece köşe noktaları saklanır.\n",
    "\n",
    "Kullanım Amacı\n",
    "\n",
    "Nesne Tespiti: Görüntüdeki nesneleri tespit etmek ve bu nesnelerin şekillerini analiz etmek için kullanılır. Konturlar, nesne izleme ve segmentasyonu gibi işlemlerde yaygın olarak kullanılır.\n",
    "\n",
    "Sonuç\n",
    "\n",
    "contours: Tespit edilen konturların bir listesini içerir. Her kontur, bir dizi nokta olarak temsil edilir.\n",
    "hierarchy: Konturlar arasındaki hiyerarşik ilişkileri tanımlar. İç içe geçmiş konturların yapısını anlamak için kullanılır.\n",
    "\n",
    "**cv2.findContours**\n",
    "\n",
    "Amaç: İkili bir görüntüde (genellikle kenar tespitinden sonra)(yani Canny'den sonra) tespit edilen şekilleri (konturları) bulmak için kullanılır.\n",
    "\n",
    "İşlem: İkili görüntüdeki beyaz alanların sınırlarını belirler ve bu sınırları bir dizi nokta olarak temsil eder.\n",
    "\n",
    "Sonuç: Kontur listeleri ve hiyerarşi bilgisi elde edilir. Konturlar, nesnelerin şekilleri hakkında bilgi sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dca474a4-343b-4802-b760-0e65652bd186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours Found = 2319\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('Sunflowers.jpg')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "print('Number of Contours Found = ' + str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image, contours,-1,(0,255,0), thickness=2)\n",
    "# bir görüntü üzerinde tespit edilen konturları çizmek için kullanılır.\n",
    "# -1 yazan kısım çizilecek contours indeksini belirtir, -1 hepsini çizer \n",
    "\n",
    "cv2.imshow('Countours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "768caa3a-f223-409b-acef-ad16814de394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burada bir örnek atladık, unutma "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412618f-2ff7-4c46-b26e-46bf8db63ce3",
   "metadata": {},
   "source": [
    "### Yüz Tanıma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80247d5b-e0ea-4541-b3bb-63c4d66a3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier (XML file format) is stored \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Load our image then convert it to grayscale \n",
    "image = cv2.imread('Foto.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# our classifier return the ROI of the detected face as a tuple\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "# faces: Tespit edilen yüzlerin koordinatlarını içeren bir liste.\n",
    "# Her yüz, bir demet (tuple) olarak (x, y, w, h) şeklinde temsil edilir.\n",
    "# face_classifier.detectMultiScale: Yüzleri tespit etmek için kullanılan metot.\n",
    "# gray: Yüzlerin tespit edileceği gri tonlamalı görüntü.\n",
    "# 1.3: Ölçek faktörü. Bu, görüntüdeki boyut değişikliklerini ayarlamak için kullanılır.\n",
    "# Daha yüksek bir değer, daha az yüz tespit eder ama daha hızlıdır.\n",
    "# 5: Minimum komşu sayısı. Bu değer, bir yüzün tespit edilmesi için gereken komşu dikdörtgen sayısını belirler.\n",
    "# Daha yüksek bir değer, daha güvenilir tespitler sağlar.\n",
    "\n",
    "# When no faces detected, face_classifier returns amd emty tuple \n",
    "if len(faces)==0 :\n",
    "    print('No faces found')\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle \n",
    "# over each face in faces\n",
    "\n",
    "for (x,y,w,h) in faces: \n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    # (x, y): Dikdörtgenin sol üst köşesinin koordinatları.\n",
    "    # (x + w, y + h): Dikdörtgenin sağ alt köşesinin koordinatları.\n",
    "    # (127,0,255) -> renk\n",
    "    # 2 -> çizgi kalınlığı \n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    # toplu olarak yüzleri bulmak istiyorsan cv2.imshow'u for'un dışını al \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7756a-5d5b-4768-b5ca-5c4078e29a74",
   "metadata": {},
   "source": [
    "**CascadeClassifier**\n",
    "\n",
    "XML Dosyası:\n",
    "\n",
    "haarcascade_frontalface_default.xml: Bu dosya, yüz tespiti için eğitilmiş bir modeldir. OpenCV'nin sağladığı Haar özelliklerine dayanan bir sınıflandırıcıdır.\n",
    "\n",
    "Kullanım:\n",
    "\n",
    "cv2.CascadeClassifier: Bu sınıf, belirtilen XML dosyasını yükler ve yüz tespiti için gerekli olan tüm bilgileri içerir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1725cea-f811-4d89-a282-a8e70fe4df54",
   "metadata": {},
   "source": [
    "**ROI, \"Region of Interest\" (İlgi Alanı)** \n",
    "Sınıflandırıcımız, tespit edilen yüzün ilgi alanını (ROI) bir demet (tuple) olarak döner. Bu demet genellikle dört değerden oluşur:\n",
    "\n",
    "x: Dikdörtgenin sol üst köşesinin x koordinatı.\n",
    "y: Dikdörtgenin sol üst köşesinin y koordinatı.\n",
    "w: Dikdörtgenin genişliği.\n",
    "h: Dikdörtgenin yüksekliği."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdfdbc96-922d-4cb6-b180-30bcaaa17a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "image = cv2.imread('insanlar.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "if len(faces)==0 :\n",
    "    print('No faces found')\n",
    "for (x,y,w,h) in faces: \n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# bu şekilde birden fazla kişi olduğunda tuşa bastıkça tek tek seçiyor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de475d84-770e-40a6-8be9-49cc1becf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "image = cv2.imread('insanlar.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "if len(faces)==0 :\n",
    "    print('No faces found')\n",
    "for (x,y,w,h) in faces: \n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    \n",
    "cv2.imshow('Face Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# bu şekilde hepsini aynı anda belirliyor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304f9d0-3ac4-4581-aa7b-0ef2bcf1e52c",
   "metadata": {},
   "source": [
    "### Yüz ve Göz Tanıma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc6146df-4455-446f-8ee1-ba91df8129b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('insanlar.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,1.3, 5)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print('No faces found')\n",
    "\n",
    "for (x,y,w,h) in faces: \n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    # ifadesi, tespit edilen yüzün gri tonlamalı görüntüdeki bölgesini(Region of Interest - ROI) \n",
    "    # almak için kullanılır. \n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "\n",
    "    for (ex,ey,ew,eh) in eyes: \n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (255,255,0), 2)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2872b-010c-4cd7-9f4b-1d471c744a04",
   "metadata": {},
   "source": [
    "roi_gray = gray[y:y+h, x:x+w] ifadesi, tespit edilen yüzün gri tonlamalı görüntüdeki alanını almak için kullanılır. Bu şekilde, yüzü izole ederek üzerinde ek işlemler yapabilirsiniz, örneğin:\n",
    "\n",
    "Yüz Tanıma: İzole edilen yüzü tanıma algoritmalarında kullanabilirsiniz.\n",
    "\n",
    "Duygu Analizi: Yüz ifadesini analiz etmek için bu bölgeyi kullanabilirsiniz.\n",
    "\n",
    "Daha Fazla İşlem: Yüz üzerinde filtreler veya dönüşümler uygulayabilirsiniz.\n",
    "\n",
    "Bu ROI (Region of Interest), yüzün özelliklerini daha iyi analiz etmenize olanak tanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "742b72d9-23d9-4a56-b3eb-d2e6b69feecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tek seferde herkesin yüzünü ve gözünü tespit etmek için \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('insanlar.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,1.3, 5)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print('No faces found')\n",
    "\n",
    "for (x,y,w,h) in faces: \n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    # ifadesi, tespit edilen yüzün gri tonlamalı görüntüdeki bölgesini(Region of Interest - ROI) \n",
    "    # almak için kullanılır. \n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray, 1.1, 2)\n",
    "\n",
    "    for (ex,ey,ew,eh) in eyes: \n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (255,255,0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "# yüz kısmını aldıktan sonra foto\n",
    "cv2.imshow('roi_color', roi_color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef2632-c421-4b10-968a-c737359d0620",
   "metadata": {},
   "source": [
    "### Videoda Yüz ve Göz Tanıma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba88313a-dc4e-4db6-b3d8-e7005a8052dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "    \n",
    "    if len(faces) ==0:\n",
    "        return img # Eğer yüz bulunamazsa orjinal görüntü dönecek \n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        x = x-5\n",
    "        w = w+10\n",
    "        y = y+30\n",
    "        h = h-20\n",
    "        # x = x - 50: Yüzün sol kenarını 50 piksel sola kaydırır.\n",
    "        # w = w + 50: Yüzün genişliğini 50 piksel artırır.\n",
    "        # y = y + 50: Yüzün üst kenarını 50 piksel aşağı kaydırır.\n",
    "        # h = h + 50: Yüzün yüksekliğini 50 piksel artırır.\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        sleep(.02)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (0,0,255), 2)\n",
    "    #img = cv2.flip(img, 1) # videoda biraz gecikmeli çalıştı ondan dolayı kapadım \n",
    "    return img \n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Face Extractor', face_detector(frame))\n",
    "\n",
    "    if cv2.waitKey(1) == 13: # 13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddf578-fb9c-42a1-9d5f-7fd6373635c9",
   "metadata": {},
   "source": [
    "img.flip(img, 1) ifadesi, görüntüyü yatay olarak tersine çevirmek için kullanılır. Yani, görüntünün sol tarafı sağ tarafa, sağ tarafı ise sol tarafa geçmiş olur. İşte bu kullanımın detayları:\n",
    "\n",
    "Neden Kullanılır?   \n",
    "Kamera Görüntüsü: Eğer görüntü bir kameradan alınıyorsa, genellikle görüntü tersine çevrilmek istenir. Örneğin, bir ayna etkisi yaratmak amacıyla kullanılır.\n",
    "\n",
    "Görsel Geri Bildirim: Kullanıcıların daha doğal bir şekilde kendilerini görmelerine yardımcı olur. Aynada gördükleri gibi bir görüntü sunar.\n",
    "\n",
    "Yüz Tespiti: Yüz tespit işlemleri sırasında, eğer görüntü tersine çevrilmemişse, kullanıcılar kendilerini doğru bir şekilde görmeyebilir. Bu, kullanıcı etkileşimini artırabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89615da3-c5c4-44ae-b3ce-f0964e229112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aşağıdaki kodu chatgpt'den hazır aldım, videoyu kaydetmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0b0f8baf-3c47-4593-85df-2e649a542490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam kare sayısı: 0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return img\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        x = x - 5\n",
    "        w = w + 10\n",
    "        y = y + 30\n",
    "        h = h - 20\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = img[y:y + h, x:x + w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        sleep(.02)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 0, 255), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Video aç\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# Kare boyutu\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# FPS - elle sabitle\n",
    "fps = 25  # Gerçek FPS yerine sabit bir değer\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS) # Bu doğru çalışıyorsa buraya al\n",
    "\n",
    "# VideoWriter tanımı\n",
    "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    processed_frame = face_detector(frame)\n",
    "    out.write(processed_frame)\n",
    "    cv2.imshow('Face Extractor', processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 13:  # Enter tuşuna basılırsa çık\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(\"Toplam kare sayısı:\", total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1327af36-eba0-42d0-a0fa-3133b2269886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-contrib-python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05e5b0-c9f6-4850-b3b7-db555d31c0be",
   "metadata": {},
   "source": [
    "### Kameradan Foto Çekme \n",
    "150 tane foto çekiceğiz, kameram olmadığı için video ile yapacağım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e30ea5b-2357-4442-a8be-09baad8488fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img, size=0.5):\n",
    "    # Convert image to grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.21, 2)\n",
    "    \n",
    "    if len(faces) ==0:\n",
    "        return None \n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "        \n",
    "    return cropped_face\n",
    "        \n",
    "\n",
    "cap = cv2.VideoCapture('My_Video.mp4')\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count +=1 \n",
    "        face = cv2.resize(face_extractor(frame), (200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "    else:\n",
    "        print('Face not found')\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break \n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b97d45f9-251e-4d90-80eb-df50a2f00345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Succesfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Training_Data, Labels = [],[] \n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    # np.asarray() liste ya da array-like alır ve bunu numpy dizisine çevirir.\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print('Model Trained Succesfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608bb10f-f2bc-46a3-b4b2-a428e6434b07",
   "metadata": {},
   "source": [
    "**model = cv2.face.LBPHFaceRecognizer_create()** ifadesi, OpenCV kütüphanesinde Lokasyon Temelli Histogram (LBPH) Yüz Tanıyıcı modelini oluşturmak için kullanılır. Bu model, yüz tanıma uygulamalarında yaygın olarak kullanılmaktadır. İşte bu modelin bazı temel özellikleri ve kullanım alanları:\n",
    "\n",
    "Temel Özellikler\n",
    "\n",
    "Yüz Tanıma:\n",
    "\n",
    "LBPH, bir yüzün özelliklerini histogramlar aracılığıyla temsil eder ve bu verileri kullanarak yüzleri tanımak için eğitilir.\n",
    "\n",
    "Eğitim:\n",
    "\n",
    "Model, çeşitli yüz görüntüleri ile eğitilir. Eğitim verisi genellikle yüz görüntüleri ve bunlara karşılık gelen etiketlerden (örneğin, kişi kimliği) oluşur.\n",
    "\n",
    "Tanıma:\n",
    "\n",
    "Eğitilen model, yeni bir yüz görüntüsü ile karşılaştığında, bu yüzün tanınmasına yardımcı olur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135274c8-2c9e-4e3a-9d95-f02b39de0379",
   "metadata": {},
   "source": [
    "**join(data_path, f)**:\n",
    "\n",
    "Bu fonksiyon, data_path dizin yolu ile f dosya adını birleştirir ve tam bir dosya yolu oluşturur. Örneğin, data_path \"images\" ve f \"photo.jpg\" ise, sonuç \"images/photo.jpg\" olur.\n",
    "\n",
    "**isfile()** ile de böyle bir uzantı olup olmadığını kontrol ettik, sonuç true döndüğünde ise f'leri liste olarak kaydettik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c188f0c1-d2bf-45e8-9b59-9499ec39576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "    \n",
    "    if len(faces) ==0:\n",
    "        return img , []\n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        x = x-5\n",
    "        w = w+10\n",
    "        y = y+30\n",
    "        h = h-20\n",
    "\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200,200))\n",
    "        \n",
    "\n",
    "    return img,roi\n",
    "\n",
    "cap = cv2.VideoCapture('My_Video.mp4')\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    image, face = face_extractor(frame)\n",
    "    try: \n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1]<500:\n",
    "            condifence = int(100 * (1-(results[1])/400))\n",
    "            display_string = str(condifence) + '% sure this is Fatih'\n",
    "            \n",
    "        cv2.putText(image, display_string, (50,120), cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        \n",
    "        if condifence > 75:\n",
    "            cv2.putText(image, 'Unlocked', (150,800), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "        else: \n",
    "            cv2.putText(image, 'Locked', (150,800), cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow('Face Recognition', image)\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, 'No Face Found', (80,120), cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image, 'Locked', (150,800), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Recognition', image)\n",
    "\n",
    "    if cv2.waitKey(50) == 13:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
